#! /home/jaggu/anaconda/bin/python2.7

"""
This script essentially analyses the shelve dictionary (generated by
pbKinetics.py) to provide graphs and csv for further analysis
"""

from __future__ import division
import shelve
import os
import sys
from operator import itemgetter
import time
import fnmatch
import itertools
# Image and Graphs
import numpy as np
import matplotlib.pyplot as plt


class Frames(object):
    """
    This provides all the analysis for information per frame (i.e. aggregated
    information of the peaks etc)
    """
    def __init__(self,framesFname):
        self.framesFname = framesFname
        self.frame_peakInfo_dict = shelve.open(framesFname)

    def photobleaching(self,nbrFrames=600):
        """ Retrieves the number of active peaks etc through the given number of
        frames. Generates a tuple of (fname,frameNbr,NbrActivePeaks,...) """
            # frameInfo = [frameNbr, number of Active Peaks, number of Inactive Peaks,
            # (Active : mean Peak Intensity, mean Background Intensity, mean snr),
            # (Inactive : ....)
        pblist = list()
        for path, val in self.frame_peakInfo_dict.items()[0:nbrFrames]:
            fname = os.path.basename(path)
            frameNbr, nbrActivePeaks,nbrInactivePeaks,activeInfo,inactiveInfo = val
            pblist.append([fname,frameNbr,nbrActivePeaks,activeInfo[0],activeInfo[1],activeInfo[2],nbrInactivePeaks, inactiveInfo[0],inactiveInfo[1],inactiveInfo[2]])
        
        return sorted(pblist,key=itemgetter(1))

    def writeFile(self,listTups,fname):
        """ Writes a csv file with the list of tuples. Names the file in the
        global destDir """
        ofname = os.path.join(destDir,fname)
        ofile = open(ofname,'w')
        for tup in listTups:
            line = "\t".join(str(item) for item in tup)
            ofile.write(line + "\n")
        ofile.close()
        return ofname

class Peak(object):
    """
    This class analyses just one peak and provides relevant information.
    # ID_x_y  == [(x,y), FrameNbr, Peak Status (1,0), Full File path, Fname
    # avgPeakIntensity (avg of 3x3 pxl), peakIntensity stdev, 
    # avgBgIntensity (16 pxl around 3x3), stdev of the Background
    # snr]
    """
    def __init__(self,peakID,frameInfo):
        self.peakID = peakID
        self.frameInfo = frameInfo
        (self.x,self.y) = frameInfo[0][0]
        (self.edgeA,self.edgeC) = ((self.x-1,self.y-1),(self.x+2,self.y+2))

    def getPeakLifetime(self):
        """Calculates the number of frames it was active (1) """
        nbrActive = [val[2] for val in self.frameInfo if val[2] == 1]
        return (len(nbrActive), len(self.frameInfo))
    def getPeakIntensity(self):
        """ Calculates the mean peak Intensity """
        peakInt_list = [val[5] for val in self.frameInfo if val[2] == 1]
        snr_list = [val[9] for val in self.frameInfo if val[2] == 1]
        return peakInt_list, snr_list


class AllPeaks(object):
    """
    This class analyses the shelve file with the peak Informations. It analysis
    it to generate a (a) csv file with Intensity, snr,  vs time (b) Draw around a
    rectangle around a peak and generate a set of images.
    """
    def __init__(self,fname):
        self.peakFname = fname
        self.peak_frameInfo_dict = shelve.open(fname)

    def getPeakLifetimes(self):
        """
        """
        for peak in self.peak_frameInfo_dict.keys():
            print peak, self.peak_frameInfo_dict[peak]
            sys.exit(1)


class GraphIt(object):
    """
    This class makes graphs like histogram etc. The important fact is it has the
    destination directory and can make the releavnt folder.
    """
    def __init__(self,dateStamp,fname):
        self.fname = fname
        self.destDir = os.path.join("/project2/marcotte/jaggu/dataAnalysis/microscope1/2014-July/",dateStamp,"peakResults","graphs",fname)
        if not os.path.exists(self.destDir): os.makedirs(self.destDir)

    def histogram(self,fname,valList,xlabel,ylabel,type):
        name = os.path.join(self.destDir,fname+'.HIST.png')
        size = ( 10,10)
        fig = plt.figure(1, figsize=(size))
        ax = fig.add_subplot(111)
        if type == 'lifetime':
            n,bins,patches = ax.hist(valList,100,facecolor='green')
        elif type == 'meanPeakIntensity':
            n,bins,patches = ax.hist(valList,1000,facecolor='grey')
        else:
            n,bins,patches = ax.hist(valList,facecolor='blue')
        ax.set_xlabel(xlabel)
        ax.set_ylabel(ylabel)
        if type == 'lifetime': 
            ax.set_xlim([0,100])
            
        plt.savefig(name)
        plt.close()
 

def test_peaks():
    shelveFname = ( 
    '/project2/marcotte/boulgakov/microscope/2014-July/2014-07-27/AS2_Atto647NSE_2aM_16hWash_647_OSS2_50Perc_trace002_flds001/shelve_test/peak_frameInfo_dict.shelve'
    )
    print shelveFname
    test = AllPeaks(shelveFname)
    print len(test.peak_frameInfo_dict)
    lifetimes_list = list()
    meanPeakInt_list = list()
    meanSNR_list = list()
    for peakID in test.peak_frameInfo_dict.keys():
        frameInfo = test.peak_frameInfo_dict[peakID]
        peak = Peak(peakID,frameInfo)
        print "Processing Peak : %s ..."%(peakID)
        act,total = peak.getPeakLifetime()
        percAct = (act/total)*100
        lifetimes_list.append(percAct)
        peak_list, snr_list = peak.getPeakIntensity()
        if peak_list: 
            meanPeakInt_list.append(np.mean(peak_list))
        if snr_list: meanSNR_list.append(np.mean(snr_list))

    dateStamp = "2014-07-29"
    fname = 'AS2_Atto647NSE_2aM_16hWash_647_OSS2_50Perc_trace002_flds001'
    all = GraphIt(dateStamp,fname)
    type = 'lifetime'
    print "Graphing ... lifetimes "
    all.histogram(fname+'.'+type,lifetimes_list,'percentage frames when peak active','frequency',type)
    type = 'meanPeakIntensity'
    print "Graphing ... Mean Peak Intensity"
    all.histogram(fname+'.'+type,meanPeakInt_list,'Mean Peak Intensity','frequency',type)
    type = 'meanSNR'
    print "Graphing ... Mean SNR"
    all.histogram(fname+'.'+type,meanSNR_list,'Mean SNR','frequency',type)





def locate(pattern, root=os.curdir):
    '''Locate all files matching supplied filename pattern in and
    below supplied root directory.'''
    allFiles = []
    for path, dirs, files in os.walk(os.path.abspath(root)):
        for filename in fnmatch.filter(files, pattern):
            allFiles.append(os.path.join(path,filename))
    return allFiles

def writeSummaryPbleaching(zipPbList,writeCols_list=[2,4,6]):
    """Writes a summary csv file for each of the writeCols_list"""
    writeCols = {'2':'Number of Active Peaks',
                   '3':'Number of Inactive Peaks',
                   '4':'Mean Active Peak Intensity',
                   '5':'Mean Background Intensity (Active peaks)',
                   '6':'Mean SNR (Active Peaks)'
                  }

    for col in writeCols_list:
        outfile = dateStamp + '_' + writeCols[str(col)] + '.RESULTS.sorted.csv'
        outCSV = os.path.join(destDir,outfile)
        ofile = open(outCSV,'w')
        # All the subsequent effort is to sort it and apply the further items in
        # the list appropriately.
        names = [item[0] for item in zipPbList[0]]
        nbrs = range(len(zipPbList[0]))
        namesTup = sorted(zip(names,nbrs),key=itemgetter(0))
        sortedNames = [i[0] for i in namesTup]
        sortingOrder = dict()
        for i,tup in enumerate(namesTup): sortingOrder[i] = tup[1]
        
        header = ["Frame Number"]
        header.extend(sortedNames)
        ofile.write("\t".join(header)+"\n")
        
        for items in zipPbList:
            rowItem = [0] * len(items)
            rowVals = list()
            for i in range(len(items)):
                try: rowVals = [str(items[i][1])]
                except TypeError: rowVals = str(0)
                try: rowItem[i] = str(items[sortingOrder[i]][col])
                except TypeError: rowItem[i] = str(0)
            try:rowVals.extend(rowItem)
            except AttributeError: 
                rowVals = ['0']
                rowVals.extend(rowItem)
            ofile.write("\t".join(rowVals)+"\n")
        ofile.close()        


def analyseTraceFrames(sourceDir):
    """ This analyses and generates frame information like photobleaching csvs
    etc """
    pattern = "frame_peakInfo_dict.shelve.dir" #.dir is the shelve file generated
    allShelves = locate(pattern,sourceDir)
    allPbList = list()
    for i, shelveFile in enumerate(allShelves):
        frame = Frames(shelveFile[:-4])
        fname = shelveFile.split('/')[-3]
        print "Processing : %s ...."%(fname)
        pblist = frame.photobleaching()
        outCSV = fname + '_RESULTS.pbleaching'+str(i)+'.csv'
        frame.writeFile(pblist,outCSV)
        allPbList.append(pblist)
        print "Processing : %s ...."%(fname)    
    # Transposes and also zips with respect to the longest list
    zipPbList = list(itertools.izip_longest(*allPbList))
    #zipPbList = zip(*allPbList) #Transposes!!
    writeSummaryPbleaching(zipPbList)



if __name__ == '__main__':
    #test_peaks()
    #sys.exit(1)
    [ARG, dateStamp] = sys.argv[1:]
    nbrFrames = 600 #This sadly is default for now. Cant fix dynamic frame numbers. 
    sourceDir = os.path.join("/project2/marcotte/boulgakov/microscope/2014-Aug/",dateStamp)
    t0 = time.clock()
    if ARG == 'FRAMES':
        destDir = os.path.join("/project2/marcotte/jaggu/dataAnalysis/microscope1/2014-Aug/",dateStamp,"traceResults_frames")
        if not os.path.exists(destDir): os.makedirs(destDir)
        analyseTraceFrames(sourceDir)
    elif ARG == 'TEST':
        destDir = os.path.join("/project2/marcotte/jaggu/dataAnalysis/microscope1/2014-July/",dateStamp,"traceResults_frames")
        if not os.path.exists(destDir): os.makedirs(destDir)
        test_frames()
    else: SystemExit("Invalid Argument") 
    t1 = time.clock()
    print ("Script - %s \t Completed in %s secs \t %s"%(sys.argv, t1-t0, time.strftime("%d %b %Y %H:%M:%S",time.localtime()))
          )

"""
############### TEST CASES #####################
def test_frames():
    shelveFname = (
    '/project2/marcotte/boulgakov/microscope/2014-July/2014-07-27/AS2_Atto647NSE_2aM_16hWash_647_OSS2_50Perc_trace002_flds001/shelve_test/frame_peakInfo_dict.shelve'
                    )
    shelveFname = (
    '/project2/marcotte/boulgakov/microscope/2014-Aug/2014-08-28/AS_Atto647N_2zM_48hlater_647_OSS_COT80_20Perc_flds_trace002/shelve/frame_peakInfo_dict.shelve.dir'
                    )
        AS_Atto647N_2zM_48hlater_647_OSS_COT80_20Perc_flds_trace002

    test = Frames(shelveFname[:-4])
    fname = shelveFname.split('/')[-3]
    print test.framesFname
    print len(test.frame_peakInfo_dict)
    pblist = test.photobleaching()
    outCSV = fname + '_RESULTS.pbleaching.csv'
    print test.writeFile(pblist,outCSV)
##################################################
"""






